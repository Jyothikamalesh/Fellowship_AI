{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":5230020,"sourceType":"datasetVersion","datasetId":3043018}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"#hide\nimport os\niskaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')\n\n\nif iskaggle:\n    %pip install -Uqq fastai ipywidgets gradio\n","metadata":{"papermill":{"duration":25.998293,"end_time":"2023-03-09T00:52:14.649721","exception":false,"start_time":"2023-03-09T00:51:48.651428","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-12-23T10:04:58.769100Z","iopub.execute_input":"2024-12-23T10:04:58.769378Z","iopub.status.idle":"2024-12-23T10:05:12.722373Z","shell.execute_reply.started":"2024-12-23T10:04:58.769358Z","shell.execute_reply":"2024-12-23T10:05:12.721492Z"},"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#hide\nfrom fastai.vision.all import *\nimport pandas as pd\n","metadata":{"papermill":{"duration":2.034376,"end_time":"2023-03-09T00:52:16.698226","exception":false,"start_time":"2023-03-09T00:52:14.66385","status":"completed"},"tags":[],"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:12.723428Z","iopub.execute_input":"2024-12-23T10:05:12.723635Z","iopub.status.idle":"2024-12-23T10:05:22.854885Z","shell.execute_reply.started":"2024-12-23T10:05:12.723618Z","shell.execute_reply":"2024-12-23T10:05:22.854259Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Loading the data","metadata":{}},{"cell_type":"markdown","source":"The fastai library provides a URLs module with a pre-specified URL for the flower dataset. We will download and extract the dataset using this module and confirm the contents of the folder by running the \"ls\" command. The folder should show a \"jpg\" folder along with \"test.txt\", \"valid.txt\" and \"train.txt\" files.","metadata":{}},{"cell_type":"code","source":"path = untar_data(URLs.FLOWERS)\n\npath.ls()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:22.856540Z","iopub.execute_input":"2024-12-23T10:05:22.856848Z","iopub.status.idle":"2024-12-23T10:05:35.347316Z","shell.execute_reply.started":"2024-12-23T10:05:22.856818Z","shell.execute_reply":"2024-12-23T10:05:35.346585Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"I have used a CSV file mapping label to a specific number,facilitating convenient programming structure.","metadata":{}},{"cell_type":"code","source":"flower_df = pd.read_csv('/kaggle/input/oxford_flower_102_name.csv', header=0)\n\nflower_index_dict = flower_df.set_index('Index').to_dict()['Name']\nprint(flower_index_dict)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:35.348385Z","iopub.execute_input":"2024-12-23T10:05:35.348671Z","iopub.status.idle":"2024-12-23T10:05:35.370338Z","shell.execute_reply.started":"2024-12-23T10:05:35.348650Z","shell.execute_reply":"2024-12-23T10:05:35.369534Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To load the `train.txt` file, we are using the pandas.read_csv function. This reads the file name and corresponding index, which is then loaded to a dataframe. We are adding an \"is_valid\" column to the dataframe to indicate whether each file will be used for training or validation process. Using the dictionary for flower name, we are adding \"label\" column.","metadata":{}},{"cell_type":"code","source":"\ndf = pd.read_csv(f'{path}/train.txt',sep=' ',names = ['fname','index'])\ndf['is_valid'] = False\ndf['label'] = df['index'].map(flower_index_dict)\n\nprint(df.shape)\n\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:35.371059Z","iopub.execute_input":"2024-12-23T10:05:35.371341Z","iopub.status.idle":"2024-12-23T10:05:35.393713Z","shell.execute_reply.started":"2024-12-23T10:05:35.371321Z","shell.execute_reply":"2024-12-23T10:05:35.393086Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Using the same steps, we are now loading the `valid.txt` file for validation data. The key difference is that the \"is_valid\" column has been assigned a value of \"True\" for each file in this dataframe, indicating that these files will be used for the validation step.","metadata":{}},{"cell_type":"code","source":"df_v = pd.read_csv(f'{path}/valid.txt',sep=' ',names = ['fname','index'])\ndf_v['is_valid'] = True\ndf_v['label'] = df_v['index'].map(flower_index_dict)\nprint(df_v.shape)\n\ndf_v.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:35.394483Z","iopub.execute_input":"2024-12-23T10:05:35.394728Z","iopub.status.idle":"2024-12-23T10:05:35.406555Z","shell.execute_reply.started":"2024-12-23T10:05:35.394709Z","shell.execute_reply":"2024-12-23T10:05:35.405753Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"To create a single dataframe, we combine the two previously created dataframes using the \"concat\" command as DataBlock expects a single datasource. We also modified the file names to contain the full path to the image files.","metadata":{}},{"cell_type":"code","source":"df = pd.concat([df,df_v])\ndf.fname = df.fname.apply(lambda x:f'{path}/{x}')\ndf.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:35.407258Z","iopub.execute_input":"2024-12-23T10:05:35.407456Z","iopub.status.idle":"2024-12-23T10:05:35.419530Z","shell.execute_reply.started":"2024-12-23T10:05:35.407440Z","shell.execute_reply":"2024-12-23T10:05:35.418870Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Image Normaliztion","metadata":{}},{"cell_type":"markdown","source":"In order to standardize the images, we are defining a transformation pipeline for CPU processing using the fastai library's RandomResizedCrop class. This transformation resizes each image to a random size of 500 pixels while maintaining the aspect ratio. The min_scale parameter specifies the minimum size of the resized image in relation to the original image. The ratio parameter controls the aspect ratio of the resized image, where (1., 1.) indicates a square aspect ratio.\n\nBy applying this transformation, the images are in a consistent size while preserving the aspect ratio and minimizing the loss of information.","metadata":{}},{"cell_type":"code","source":"item_tfms = [RandomResizedCrop(500,min_scale=0.75, ratio=(1.,1.))]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:35.421651Z","iopub.execute_input":"2024-12-23T10:05:35.421885Z","iopub.status.idle":"2024-12-23T10:05:35.434455Z","shell.execute_reply.started":"2024-12-23T10:05:35.421866Z","shell.execute_reply":"2024-12-23T10:05:35.433844Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"At this step, we are defining a batch transformation pipeline using the fastai library's aug_transforms and Normalize classes suitable for GPU setting.\n\nThe aug_transforms function applies a set of image augmentations, such as flipping, rotating, and zooming, to the images in our dataset to add variations to the images. The size parameter specifies the desired size of the transformed images, which in this case is 244 pixels. I chose to augment because the number of images per category is not too high so augmentation will add diversity for the model.\n\nIn the Normalize, the from_stats method is used to specify the normalization statistics, which in this case are the mean and standard deviation values from the ImageNet dataset.\n","metadata":{}},{"cell_type":"code","source":"batch_tfms = [*aug_transforms(size=244),Normalize.from_stats(*imagenet_stats)]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:35.435541Z","iopub.execute_input":"2024-12-23T10:05:35.435752Z","iopub.status.idle":"2024-12-23T10:05:35.792632Z","shell.execute_reply.started":"2024-12-23T10:05:35.435734Z","shell.execute_reply":"2024-12-23T10:05:35.791954Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Creating datablock","metadata":{}},{"cell_type":"markdown","source":"It's time to build the datablock to train and validate the model. \n* (ImageBlock, CategoryBlock) specifies the types of data blocks to use for our input images and output categories\n* get_x=ColReader('fname') and get_y=ColReader('index') are used to specify the input and output data columns.\n* item_tfms=item_tfms and batch_tfms=batch_tfms specify the transformation pipelines to apply to our input data items and batches\n* splitter=ColSplitter() is used to specify how to split our dataset into training and validation sets. It will use the column 'is_valid' we defined earlier.\n","metadata":{}},{"cell_type":"code","source":"dblock = DataBlock((ImageBlock,CategoryBlock),\n                   get_x=ColReader('fname'),\n                   get_y = ColReader('label'),\n                   item_tfms = item_tfms,\n                   batch_tfms= batch_tfms,\n                   splitter=ColSplitter()                  \n                  )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:35.793294Z","iopub.execute_input":"2024-12-23T10:05:35.793506Z","iopub.status.idle":"2024-12-23T10:05:35.798772Z","shell.execute_reply.started":"2024-12-23T10:05:35.793488Z","shell.execute_reply":"2024-12-23T10:05:35.798011Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now, the datablock is defined. We can get hold of dataloader object by applying the transformations defined in the 'DataBlock' object to our input dataframe, `df`. \nFor visual inspection, `dls.show_batch()` is then used to display a batch of the transformed data. ","metadata":{}},{"cell_type":"code","source":"dls = dblock.dataloaders(df)\ndls.show_batch()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:05:35.799411Z","iopub.execute_input":"2024-12-23T10:05:35.799628Z","iopub.status.idle":"2024-12-23T10:05:39.023432Z","shell.execute_reply.started":"2024-12-23T10:05:35.799609Z","shell.execute_reply":"2024-12-23T10:05:39.022268Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Learning with Resnet50","metadata":{}},{"cell_type":"markdown","source":"We used the pretrained model, `resnet50` to train the model using the dataloader created before. I chose error rate as a `metrics` parameter to measure the performance of each run. \n","metadata":{}},{"cell_type":"code","source":"learn_resnet50 = vision_learner(dls, resnet50, metrics=error_rate)\nlearn_resnet50.fine_tune(6)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:45:15.120435Z","iopub.execute_input":"2024-12-23T10:45:15.120810Z","iopub.status.idle":"2024-12-23T10:47:47.067240Z","shell.execute_reply.started":"2024-12-23T10:45:15.120777Z","shell.execute_reply":"2024-12-23T10:47:47.066333Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"fine_tune function allows us to utilize inbuilt Gradient Descent algorithm to finetune the model to Oxford 102 Flower Dataset","metadata":{}},{"cell_type":"code","source":"interp_res50 = ClassificationInterpretation.from_learner(learn_resnet50)\ninterp_res50.plot_confusion_matrix(figsize=(10,10))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:48:07.902764Z","iopub.execute_input":"2024-12-23T10:48:07.903114Z","iopub.status.idle":"2024-12-23T10:48:41.605110Z","shell.execute_reply.started":"2024-12-23T10:48:07.903087Z","shell.execute_reply":"2024-12-23T10:48:41.604076Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"We can list some top losses (5 in this case) to understand what it went wrong. ","metadata":{}},{"cell_type":"code","source":"interp_res50.plot_top_losses(5, nrows=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:48:41.606598Z","iopub.execute_input":"2024-12-23T10:48:41.606930Z","iopub.status.idle":"2024-12-23T10:48:42.558844Z","shell.execute_reply.started":"2024-12-23T10:48:41.606898Z","shell.execute_reply":"2024-12-23T10:48:42.557733Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\nlearn_resnet50.export(os.path.join('/kaggle/working', 'export.pkl'))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:49:05.389767Z","iopub.execute_input":"2024-12-23T10:49:05.390216Z","iopub.status.idle":"2024-12-23T10:49:05.685807Z","shell.execute_reply.started":"2024-12-23T10:49:05.390182Z","shell.execute_reply":"2024-12-23T10:49:05.684839Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"In order to use the exported model file, `load_learner` is called to create an inference object. The inference object also has the access to label vocab to show the prediction value.","metadata":{}},{"cell_type":"code","source":"learn_inf = load_learner('/kaggle/working/export.pkl')\nlearn_inf.dls.vocab","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:49:37.699009Z","iopub.execute_input":"2024-12-23T10:49:37.699304Z","iopub.status.idle":"2024-12-23T10:49:37.775904Z","shell.execute_reply.started":"2024-12-23T10:49:37.699280Z","shell.execute_reply":"2024-12-23T10:49:37.775037Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here is the content for app.py that defines the interface for the UI and service api.","metadata":{}},{"cell_type":"code","source":"from fastai.vision.all import * \nimport gradio as gr\nfrom PIL import Image\n\nlearn_inf = load_learner('/kaggle/working/export.pkl')\nlabels = learn_inf.dls.vocab\ndef predict(img):\n    img = Image.fromarray(img)\n    img = img.resize((512, 512))\n    pred,pred_idx,probs = learn_inf.predict(img)\n    return {labels[i]: float(probs[i]) for i in range(len(labels))}\n\ntitle = \"Flower Classifier\"\ndescription = \"Flower classifier for 102 types of flowers\"\narticle=\"<p style='text-align: center'><a href='https://imju.me' target='_blank'>Blog post</a></p>\"\ninterpretation='default'\nenable_queue=True\n\ngr.Interface(\n    fn=predict, \n    inputs=gr.Image(type=\"numpy\"), \n    outputs=gr.Label(num_top_classes=3)\n).launch(inbrowser=False, share=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-23T10:49:48.862760Z","iopub.execute_input":"2024-12-23T10:49:48.863064Z","iopub.status.idle":"2024-12-23T10:49:49.321157Z","shell.execute_reply.started":"2024-12-23T10:49:48.863039Z","shell.execute_reply":"2024-12-23T10:49:49.320402Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}